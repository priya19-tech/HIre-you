<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>shot level Quiz</title>
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }

    body {
      height: 100vh;
      background: linear-gradient(to right, #e0c3fc, #8ec5fc);
      font-family: 'Segoe UI', sans-serif;
      display: flex;
      align-items: center;
      justify-content: center;
      animation: fadeIn 1s ease-in;
    }

    @keyframes fadeIn {
      from { opacity: 0; transform: scale(0.9); }
      to { opacity: 1; transform: scale(1); }
    }

    .quiz-box {
      background: white;
      width: 90%;
      max-width: 600px;
      padding: 30px;
      border-radius: 20px;
      box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
      text-align: center;
    }

    .quiz-title {
      font-size: 28px;
      font-weight: bold;
      margin-bottom: 20px;
      background: linear-gradient(to right, #4b0082, #8a2be2);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
    }

    .question {
      font-size: 20px;
      margin-bottom: 20px;
      color: #333;
    }

    .choices {
      display: flex;
      flex-direction: column;
      gap: 12px;
      margin-bottom: 20px;
    }

    .choice {
      background: #f1f1ff;
      padding: 12px;
      border-radius: 10px;
      cursor: pointer;
      transition: background 0.3s ease;
      border: 2px solid transparent;
    }

    .choice:hover {
      background: #ddd5ff;
    }

    .correct {
      background-color: #d4edda;
      border-color: #28a745;
    }

    .wrong {
      background-color: #f8d7da;
      border-color: #dc3545;
    }

    .explanation {
      font-size: 16px;
      color: #444;
    }

    button {
      background: #6a0dad;
      color: white;
      padding: 12px 24px;
      border: none;
      border-radius: 8px;
      font-size: 16px;
      cursor: pointer;
      margin-top: 20px;
    }

    button:hover {
      background: #4b0082;
    }
  </style>
</head>
<body>

  <div class="quiz-box">
    <div class="quiz-title">LEVEL 5</div>
    <div class="question" id="question">Loading...</div>
    <div class="choices" id="choices"></div>
    <div class="explanation" id="explanation"></div>
    <button onclick="nextQuestion()" id="nextBtn">Next</button>
  </div>

  <script>


const questions = [
  {
    question: "If a task involves a niche domain (e.g., legal contracts) not commonly seen during training, which prompt style is likely more reliable?",
    choice1: "Zero-shot",
    choice2: "Few-shot",
    choice3: "Fine-tuning",
    choice4: "One-shot",
    answer: 2,
    explanation: "Few-shot allows the user to introduce domain-specific context and task patterns through examples, improving the model‚Äôs ability to generalize appropriately even in unfamiliar contexts."
  },
  {
    question: "A prompt uses 5 examples of sentiment classification. The input and output tokens per example are 25 tokens. If the instruction is 20 tokens long, what is the total token usage before the test input?",
    choice1: "145 tokens",
    choice2: "1450 tokens",
    choice3: "145 tokens + test input",
    choice4: "120 tokens",
    answer: 3,
    explanation: "Each example: 25 tokens\n5 examples ‚Üí 5 √ó 25 = 125\nInstruction = 20 tokens ‚Üí Total = 125 + 20 = 145 tokens (excluding test input)"
  },
  {
    question: "Why might few-shot prompting fail even when examples are correct?",
    choice1: "The model doesn't read examples",
    choice2: "The model only supports zero-shot",
    choice3: "Examples are too complex or inconsistent",
    choice4: "Model requires training first",
    answer: 3,
    explanation: "If examples vary in structure, tone, or task representation, the model might not extract the intended pattern and give inconsistent outputs."
  },
  {
    question: "You use 4 examples in a prompt, each 30 tokens long. The model‚Äôs token limit is 2048. What's the max token budget left for the actual input and output?",
    choice1: "1928",
    choice2: "1920",
    choice3: "192",
    choice4: "1928 tokens",
    answer: 2,
    explanation: "4 examples √ó 30 tokens = 120 tokens\nToken budget left = 2048 ‚àí 120 = 1928 tokens, but if you also include the instruction (say, 8 tokens), remaining budget = 1920 tokens."
  },
  {
    question: "Few-shot is preferred over zero-shot when:",
    choice1: "The task is general knowledge",
    choice2: "Output needs to mimic specific format",
    choice3: "Task is too simple",
    choice4: "Token budget is limited",
    answer: 2,
    explanation: "Few-shot helps guide the output format using example structure, which is especially useful when the model needs to mimic a desired output format or pattern."
  },
  {
    question: "Which situation best illustrates a use-case where zero-shot fails but few-shot succeeds?",
    choice1: "Translate 'Hola' to English.",
    choice2: "Add two numbers: 3 + 4",
    choice3: "Summarize scientific paragraphs in academic tone.",
    choice4: "Tell a joke",
    answer: 3,
    explanation: "Complex stylistic tasks like summarizing in a specific tone require demonstration, which zero-shot lacks. Few-shot provides that tone/style example."
  },
  {
    question: "In a few-shot prompt with 6 examples, why might performance drop after adding the 7th?",
    choice1: "Model resets",
    choice2: "Examples lose pattern clarity",
    choice3: "Token limit exceeded, truncating prompt",
    choice4: "Model forgets earlier data",
    answer: 3,
    explanation: "If the total token count exceeds the model‚Äôs context window, the model may truncate earlier parts of the prompt (which include crucial instructions or examples)."
  },
  {
    question: "In few-shot learning, adding irrelevant examples can:",
    choice1: "Improve generalization",
    choice2: "Increase accuracy",
    choice3: "Confuse the model",
    choice4: "Reduce token usage",
    answer: 3,
    explanation: "The model attempts to infer task patterns from provided examples. Irrelevant ones confuse the objective and harm performance."
  },
  {
    question: "Why is few-shot prompting not always the best solution?",
    choice1: "It‚Äôs expensive to fine-tune",
    choice2: "It doesn‚Äôt support examples",
    choice3: "It may consume too many tokens",
    choice4: "It performs worse than zero-shot",
    answer: 3,
    explanation: "While powerful, few-shot increases token consumption due to added examples, reducing efficiency when token space is limited."
  },
  {
    question: "When crafting few-shot examples, which principle ensures consistency in output?",
    choice1: "Creativity",
    choice2: "Example diversity",
    choice3: "Structured format",
    choice4: "Compression",
    answer: 3,
    explanation: "Keeping all examples in a consistent structure (input/output format, language style, tone) helps the model generalize the intended task accurately."
  }
];

let current = 0;
    let score = 0;

    function loadQuestion() {
      const q = questions[current];
      document.getElementById('question').textContent = q.question;
      const choicesDiv = document.getElementById('choices');
      choicesDiv.innerHTML = '';
      document.getElementById('explanation').textContent = '';

      for (let i = 1; i <= 9; i++) {
        if (q['choice' + i]) {
          const btn = document.createElement('div');
          btn.className = 'choice';
          btn.textContent = q['choice' + i];
          btn.onclick = () => checkAnswer(i, btn);
          choicesDiv.appendChild(btn);
        }
      }
    }

    function checkAnswer(selected, element) {
      const q = questions[current];
      const allChoices = document.querySelectorAll('.choice');

      allChoices.forEach(c => c.onclick = null);

      if (selected === q.answer) {
        element.classList.add('correct');
        score++;
      } else {
        element.classList.add('wrong');
        allChoices[q.answer - 1].classList.add('correct');
      }

      document.getElementById('explanation').textContent = "üìù " + q.explanation;
    }

    function nextQuestion() {
      current++;
      if (current < questions.length) {
        loadQuestion();
      } else {
        const box = document.querySelector('.quiz-box');
        if (score === questions.length) {
          box.innerHTML = `
            <h2>üéâ Perfect Score: ${score}/${questions.length}</h2>
            <p>You‚Äôre ready for the next level!</p>
            <button onclick="window.location.href='shotlev6.html'">Go to Level 6 üöÄ</button>

          `;
        } else {
          box.innerHTML = `
            <h2>üò¢ You scored ${score}/${questions.length}</h2>
            <p>You need 10/10 to move on. Try again!</p>
            <button onclick="restart()">Retry üîÅ</button>
          `;
        }
      }
    }

    function restart() {
  current = 0; // Reset question index to the beginning of the current level
  score = 0; // Reset score
  window.location.href = 'shotlev5.html'; // Redirect to Level 2 directly
}


    loadQuestion();
  </script>

</body>
</html>

