<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AI ENGG - 3 Quiz</title>
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }

    body {
      height: 100vh;
      background: linear-gradient(to right, #e0c3fc, #8ec5fc);
      font-family: 'Segoe UI', sans-serif;
      display: flex;
      align-items: center;
      justify-content: center;
      animation: fadeIn 1s ease-in;
    }

    @keyframes fadeIn {
      from { opacity: 0; transform: scale(0.9); }
      to { opacity: 1; transform: scale(1); }
    }

    .quiz-box {
      background: white;
      width: 90%;
      max-width: 600px;
      padding: 30px;
      border-radius: 20px;
      box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
      text-align: center;
    }

    .quiz-title {
      font-size: 28px;
      font-weight: bold;
      margin-bottom: 20px;
      background: linear-gradient(to right, #4b0082, #8a2be2);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
    }

    .question {
      font-size: 20px;
      margin-bottom: 20px;
      color: #333;
    }

    .choices {
      display: flex;
      flex-direction: column;
      gap: 12px;
      margin-bottom: 20px;
    }

    .choice {
      background: #f1f1ff;
      padding: 12px;
      border-radius: 10px;
      cursor: pointer;
      transition: background 0.3s ease;
      border: 2px solid transparent;
    }

    .choice:hover {
      background: #ddd5ff;
    }

    .correct {
      background-color: #d4edda;
      border-color: #28a745;
    }

    .wrong {
      background-color: #f8d7da;
      border-color: #dc3545;
    }

    .explanation {
      font-size: 16px;
      color: #444;
    }

    button {
      background: #6a0dad;
      color: white;
      padding: 12px 24px;
      border: none;
      border-radius: 8px;
      font-size: 16px;
      cursor: pointer;
      margin-top: 20px;
    }

    button:hover {
      background: #4b0082;
    }
  </style>
</head>
<body>

  <div class="quiz-box">
    <div class="quiz-title">LEVEL 7</div>
    <div class="question" id="question">Loading...</div>
    <div class="choices" id="choices"></div>
    <div class="explanation" id="explanation"></div>
    <button onclick="nextQuestion()" id="nextBtn">Next</button>
  </div>

  <script>



const questions = [
  {
    question: "What does SGD stand for in the context of optimization algorithms?",
    options: [
      "A) Slow Gradient Descent",
      "B) Stochastic Gradient Descent",
      "C) Strong Gradient Dynamics",
      "D) Sparse Gradient Downsampling"
    ],
    answer: 1,
    explanation: "SGD stands for Stochastic Gradient Descent, where model parameters are updated using random subsets (mini-batches) of the data."
  },
  {
    question: "Which of the following optimization algorithms adapts the learning rate for each parameter using estimates of first and second moments?",
    options: [
      "A) SGD",
      "B) RMSprop",
      "C) Adam",
      "D) AdaGrad"
    ],
    answer: 2,
    explanation: "Adam uses both the mean (1st moment) and the uncentered variance (2nd moment) of gradients to adapt learning rates."
  },
  {
    question: "What is the main benefit of using learning rate schedules?",
    options: [
      "A) Prevents overfitting",
      "B) Helps convergence by adjusting learning rate over time",
      "C) Reduces the need for backpropagation",
      "D) Increases batch size dynamically"
    ],
    answer: 1,
    explanation: "Learning rate schedules lower the learning rate over time to allow more stable convergence."
  },
  {
    question: "Which optimizer is typically best suited for sparse data?",
    options: [
      "A) Adam",
      "B) SGD",
      "C) RMSprop",
      "D) Momentum"
    ],
    answer: 0,
    explanation: "Adam handles sparse gradients well due to its adaptive learning rates, especially in NLP tasks."
  },
  {
    question: "Which of these optimization methods uses an exponentially decaying average of past gradients to normalize updates?",
    options: [
      "A) SGD",
      "B) RMSprop",
      "C) Adamax",
      "D) Nesterov"
    ],
    answer: 1,
    explanation: "RMSprop normalizes the gradient using a moving average of squared gradients, stabilizing updates."
  },
  {
    question: "In gradient descent, what does a very high learning rate usually cause?",
    options: [
      "A) Faster convergence",
      "B) Divergence or oscillation",
      "C) Overfitting",
      "D) Zero gradients"
    ],
    answer: 1,
    explanation: "A high learning rate may cause the model to overshoot minima, leading to divergence or oscillation."
  },
  {
    question: "Which optimization algorithm combines momentum and RMSprop?",
    options: [
      "A) Nesterov",
      "B) Adam",
      "C) AdaGrad",
      "D) FTRL"
    ],
    answer: 1,
    explanation: "Adam blends momentum (velocity) and RMSprop (adaptive learning rates) into one powerful optimizer."
  },
  {
    question: "What does learning rate decay do during training?",
    options: [
      "A) Increases the loss gradually",
      "B) Reduces learning rate as epochs increase",
      "C) Increases weight updates",
      "D) Keeps learning rate constant"
    ],
    answer: 1,
    explanation: "Learning rate decay reduces the step size as training progresses, preventing overshooting near minima."
  },
  {
    question: "Which of the following optimizers may lead to very small updates as training progresses due to accumulated squared gradients?",
    options: [
      "A) RMSprop",
      "B) AdaGrad",
      "C) Adam",
      "D) SGD"
    ],
    answer: 1,
    explanation: "AdaGrad's accumulated squared gradients can make updates very small, slowing or halting learning."
  },
  {
    question: "What is the purpose of momentum in optimization?",
    options: [
      "A) Reduce batch size",
      "B) Introduce noise",
      "C) Accelerate updates in consistent gradient directions",
      "D) Adjust learning rate automatically"
    ],
    answer: 2,
    explanation: "Momentum helps the optimizer continue in the direction of consistent gradients, speeding up convergence and reducing oscillation."
  }
];







let current = 0;
    let score = 0;

    function loadQuestion() {
    const q = questions[current];
    document.getElementById('question').textContent = q.question;
    const choicesDiv = document.getElementById('choices');
    choicesDiv.innerHTML = '';
    document.getElementById('explanation').textContent = '';

    q.options.forEach((option, index) => {
      const btn = document.createElement('div');
      btn.className = 'choice';
      btn.textContent = option;
      btn.onclick = () => checkAnswer(index, btn);
      choicesDiv.appendChild(btn);
    });
  }

  function checkAnswer(selected, element) {
    const q = questions[current];
    const allChoices = document.querySelectorAll('.choice');

    allChoices.forEach(c => c.onclick = null);

    if (selected === q.answer) {
      element.classList.add('correct');
      score++;
    } else {
      element.classList.add('wrong');
      allChoices[q.answer].classList.add('correct');
    }

    document.getElementById('explanation').textContent = "üìù " + q.explanation;
  }

    function nextQuestion() {
      current++;
      if (current < questions.length) {
        loadQuestion();
      } else {
        const box = document.querySelector('.quiz-box');
        if (score === questions.length) {
          box.innerHTML = `
            <h2>üéâ Perfect Score: ${score}/${questions.length}</h2>
            <p>You‚Äôre ready for the next level!</p>
            <button onclick="window.location.href='3l8.html'">Go to Level 8 ! üöÄ</button>

          `;
        } else {
          box.innerHTML = `
            <h2>üò¢ You scored ${score}/${questions.length}</h2>
            <p>You need 10/10 to move on. Try again!</p>
            <button onclick="restart()">Retry üîÅ</button>
          `;
        }
      }
    }

    function restart() {
  current = 0; // Reset question index to the beginning of the current level
  score = 0; // Reset score
  window.location.href = '3l7.html'; // Redirect to Level 2 directly
}
    loadQuestion();
  </script>

</body>
</html>

